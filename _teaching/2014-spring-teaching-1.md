---
title: "2024第八届中山大学人工社会与计算社会科学讲习班"
collection: teaching
type: "暑期学校 Summer School"
permalink: /teaching/2024-spring-teaching-1
venue: "中山大学 Sun-yat Sen University"
date: 2024-07-27
location: "广州"
---

<aside>
💡 本页给出讲习班中所涉及到的生成式人工智能资源汇总，请各位老师同学按需自取。

</aside>

# 一、生成式人工智能介绍

GPT3训练过程和模型表现介绍：[2005.14165.pdf (arxiv.org)](https://arxiv.org/pdf/2005.14165.pdf)

GPT4 技术报告：[https://cdn.openai.com/papers/gpt-4.pdf](https://cdn.openai.com/papers/gpt-4.pdf)

Google cloud 大语言模型和生成式人工智能介绍：

[Introduction to large language models](https://www.youtube.com/watch?v=zizonToFXDs&t=183s)

[Introduction to Generative AI](https://www.youtube.com/watch?v=G2fqAlgmoPo&list=PLVNg_HxzYZ12xJA6SEyEwaBhpwvqCVTlH&index=16&t=688s)

大模型相关的综述

[](https://osf.io/preprints/socarxiv/rwtzs/)

[AI and the transformation of social science research](https://www.science.org/doi/full/10.1126/science.adi1778)

[Challenges and Applications of Large Language Models](http://arxiv.org/abs/2307.10169)

大模型相关的研究1：AI对话助手研究

[AI Chat Assistants can Improve Conversations about Divisive Topics](http://arxiv.org/abs/2302.07268)

大模型相关的研究2：

[Out of One, Many: Using Language Models to Simulate Human Samples | Political Analysis | Cambridge Core](https://www.cambridge.org/core/journals/political-analysis/article/abs/out-of-one-many-using-language-models-to-simulate-human-samples/035D7C8A55B237942FB6DBAD7CAA4E49)

大模型相关的研究3

[Generative Agents: Interactive Simulacra of Human Behavior](http://arxiv.org/abs/2304.03442)

# 二、使用生成式人工智能辅助科研

## 1. 使用AI

国外的大语言模型列表

- https://chat.openai.com
- https://claude.ai/chat/
- https://bard.google.com/
- https://www.bing.com/new

国内可用的免费ChatGPT镜像列表：[https://github.com/LiLittleCat/awesome-free-chatgpt](https://github.com/LiLittleCat/awesome-free-chatgpt)

中国大语言模型百模大战参考资料：[GitHub - wgwang/LLMs-In-China: 中国大模型](https://github.com/wgwang/LLMs-In-China)

吴恩达提示词工程教程【免费】：

[ChatGPT Prompt Engineering for Developers - DeepLearning.AI](https://www.deeplearning.ai/short-courses/chatgpt-prompt-engineering-for-developers/)

## 2. 使用API

注册账号的方法可参考：[https://chatgptboke.com/how-to-register-chatgpt-in-china.html](https://chatgptboke.com/how-to-register-chatgpt-in-china.html)

获得账号API：[https://platform.openai.com/account/api-keys](https://platform.openai.com/account/api-keys)

获得API key，可以试试微软的Azure： [https://learn.microsoft.com/zh-cn/azure/ai-services/openai/chatgpt-quickstart?tabs=command-line&pivots=programming-language-studio](https://learn.microsoft.com/zh-cn/azure/ai-services/openai/chatgpt-quickstart?tabs=command-line&pivots=programming-language-studio)和[https://www.sunpop.cn/chatgpt_in_china_with_azure_openai_api_free_1_year_odoo/](https://www.sunpop.cn/chatgpt_in_china_with_azure_openai_api_free_1_year_odoo/)

大模型质量对比

# 3.使用插件

浏览器AI插件大全：

[卡兹克-GPT Plugin评测大全](https://docs.qq.com/sheet/DT3lqTk9HTlpuZlJK?tab=BB08J2&scode=)

在zotero中使用GPT

[https://github.com/MuiseDestiny/zotero-gpt/releases/tag/0.2.9](https://github.com/MuiseDestiny/zotero-gpt/releases/tag/0.2.9)

集成的GPT学术： [https://github.com/WangXinluan/ChatGPT-Academic](https://github.com/WangXinluan/ChatGPT-Academic)

在R语言中使用ChatGPT教程

- [https://www.infoworld.com/article/3694611/8-chatgpt-tools-for-r-programming.html](https://www.infoworld.com/article/3694611/8-chatgpt-tools-for-r-programming.html)
- [https://www.listendata.com/2023/05/chatgpt-in-r.html#terminologies_related_to_chatgpt](https://www.listendata.com/2023/05/chatgpt-in-r.html#terminologies_related_to_chatgpt)
- [https://github.com/gexijin/RTutor](https://github.com/gexijin/RTutor)

本地部署参考： [ChatGLM-6B 本地部署指南！ (qq.com)](https://mp.weixin.qq.com/s/545Z4DTB78q_sLqBq6dC1A)

文献阅读工具：

[https://www.chatpdf.com/](https://www.chatpdf.com/)

[ChatDOC - Chat with your documents](https://chatdoc.com/)

[Humata - GPT for your files](https://www.humata.ai/)

数据分析prompt：

- [https://docs.kanaries.net/articles/chatgpt-prompt-data-scientist](https://docs.kanaries.net/articles/chatgpt-prompt-data-scientist)
- [https://clickup.com/templates/ai-prompts/data-analysis](https://clickup.com/templates/ai-prompts/data-analysis)

密西西比州立大学社会科学研究中心收集了可以被应用于社会科学的AI工具：

包含 250 个对社会科学研究有用的人工智能 (AI) 应用程序的数据库。要纳入我们的数据库，人工智能工具必须适用于：1）文献综述、摘要或写作，2）数据收集、分析或可视化，或 3）研究传播。

[https://docs.google.com/spreadsheets/d/19HER-PsGbCuczLlzpw9l--j5mMQHtv-YIawLg-g5Q0M/edit?gid=2011647662#gid=2011647662](https://docs.google.com/spreadsheets/d/19HER-PsGbCuczLlzpw9l--j5mMQHtv-YIawLg-g5Q0M/edit?gid=2011647662#gid=2011647662)

## 案例

LLM辅助的计算社会科学实践：https://github.com/openai/openai-cookbook

智能小镇

- 开源代码链接：[https://github.com/joonspk-research/generative_agents](https://github.com/joonspk-research/generative_agents)
- 项目demo链接：[https://reverie.herokuapp.com/arXiv_Demo/](https://reverie.herokuapp.com/arXiv_Demo/)

问卷机器人：

# 三、人工智能应用前景和伦理

[生成式人工智能服务管理暂行办法_中央网络安全和信息化委员会办公室](http://www.cac.gov.cn/2023-07/13/c_1690898327029107.htm)

Abid, A., Farooqi, M., & Zou, J. (2021). Large language models associate Muslims with violence. *Nature Machine Intelligence*, *3*(6), Article 6. [https://doi.org/10.1038/s42256-021-00359-2](https://doi.org/10.1038/s42256-021-00359-2)

Brown, T. B., Mann, B., Ryder, N., Subbiah, M., Kaplan, J., Dhariwal, P., Neelakantan, A., Shyam, P., Sastry, G., Askell, A., Agarwal, S., Herbert-Voss, A., Krueger, G., Henighan, T., Child, R., Ramesh, A., Ziegler, D. M., Wu, J., Winter, C., … Amodei, D. (2020). *Language Models are Few-Shot Learners*. [https://doi.org/10.48550/ARXIV.2005.14165](https://doi.org/10.48550/ARXIV.2005.14165)

Dodge, J., Sap, M., Marasović, A., Agnew, W., Ilharco, G., Groeneveld, D., Mitchell, M., & Gardner, M. (2021). *Documenting Large Webtext Corpora: A Case Study on the Colossal Clean Crawled Corpus* (arXiv:2104.08758). arXiv. [https://doi.org/10.48550/arXiv.2104.08758](https://doi.org/10.48550/arXiv.2104.08758)

Gao, L., Biderman, S., Black, S., Golding, L., Hoppe, T., Foster, C., Phang, J., He, H., Thite, A., Nabeshima, N., Presser, S., & Leahy, C. (2020). *The Pile: An 800GB Dataset of Diverse Text for Language Modeling* (arXiv:2101.00027). arXiv. [https://doi.org/10.48550/arXiv.2101.00027](https://doi.org/10.48550/arXiv.2101.00027)

Gehman, S., Gururangan, S., Sap, M., Choi, Y., & Smith, N. A. (2020). RealToxicityPrompts: Evaluating Neural Toxic Degeneration in Language Models. *Findings of the Association for Computational Linguistics: EMNLP 2020*, 3356–3369. [https://doi.org/10.18653/v1/2020.findings-emnlp.301](https://doi.org/10.18653/v1/2020.findings-emnlp.301)

Hao, R., Hu, L., Qi, W., Wu, Q., Zhang, Y., & Nie, L. (2023). *ChatLLM Network: More brains, More intelligence* (arXiv:2304.12998). arXiv. [https://doi.org/10.48550/arXiv.2304.12998](https://doi.org/10.48550/arXiv.2304.12998)

Kaddour, J., Harris, J., Mozes, M., Bradley, H., Raileanu, R., & McHardy, R. (2023). *Challenges and Applications of Large Language Models* (arXiv:2307.10169). arXiv. [https://doi.org/10.48550/arXiv.2307.10169](https://doi.org/10.48550/arXiv.2307.10169)

Kreutzer, J., Caswell, I., Wang, L., Wahab, A., van Esch, D., Ulzii-Orshikh, N., Tapo, A., Subramani, N., Sokolov, A., Sikasote, C., Setyawan, M., Sarin, S., Samb, S., Sagot, B., Rivera, C., Rios, A., Papadimitriou, I., Osei, S., Suarez, P. O., … Adeyemi, M. (2022). Quality at a Glance: An Audit of Web-Crawled Multilingual Datasets. *Transactions of the Association for Computational Linguistics*, *10*, 50–72. [https://doi.org/10.1162/tacl_a_00447](https://doi.org/10.1162/tacl_a_00447)

Lee, K., Ippolito, D., Nystrom, A., Zhang, C., Eck, D., Callison-Burch, C., & Carlini, N. (2022). *Deduplicating Training Data Makes Language Models Better* (arXiv:2107.06499). arXiv. [https://doi.org/10.48550/arXiv.2107.06499](https://doi.org/10.48550/arXiv.2107.06499)

Li, M., Roller, S., Kulikov, I., Welleck, S., Boureau, Y.-L., Cho, K., & Weston, J. (2020). *Don’t Say That! Making Inconsistent Dialogue Unlikely with Unlikelihood Training* (arXiv:1911.03860). arXiv. [https://doi.org/10.48550/arXiv.1911.03860](https://doi.org/10.48550/arXiv.1911.03860)

Liu, R., Yang, R., Jia, C., Zhang, G., Zhou, D., Dai, A. M., Yang, D., & Vosoughi, S. (2023). *Training Socially Aligned Language Models in Simulated Human Society* (arXiv:2305.16960). arXiv. [https://doi.org/10.48550/arXiv.2305.16960](https://doi.org/10.48550/arXiv.2305.16960)

Nadeem, M., Bethke, A., & Reddy, S. (2021). StereoSet: Measuring stereotypical bias in pretrained language models. *Proceedings of the 59th Annual Meeting of the Association for Computational Linguistics and the 11th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)*, 5356–5371. [https://doi.org/10.18653/v1/2021.acl-long.416](https://doi.org/10.18653/v1/2021.acl-long.416)

Raﬀel, C., Shazeer, N., Roberts, A., Lee, K., Narang, S., Matena, M., Zhou, Y., Li, W., & Liu, P. J. (n.d.). *Exploring the Limits of Transfer Learning with a Uniﬁed Text-to-Text Transformer*.

Ung, M., Xu, J., & Boureau, Y.-L. (2022). *SaFeRDialogues: Taking Feedback Gracefully after Conversational Safety Failures* (arXiv:2110.07518). arXiv. [https://doi.org/10.48550/arXiv.2110.07518](https://doi.org/10.48550/arXiv.2110.07518)

Wang, S., Liu, Y., Xu, Y., Zhu, C., & Zeng, M. (2021). *Want To Reduce Labeling Cost? GPT-3 Can Help* (arXiv:2108.13487). arXiv. [http://arxiv.org/abs/2108.13487](http://arxiv.org/abs/2108.13487)

Yuan, L., Gao, X., Zheng, Z., Edmonds, M., Wu, Y. N., Rossano, F., Lu, H., Zhu, Y., & Zhu, S.-C. (2022). In situ bidirectional human-robot value alignment. *Science Robotics*, *7*(68), eabm4183. [https://doi.org/10.1126/scirobotics.abm4183](https://doi.org/10.1126/scirobotics.abm4183)

Zhao, J., Wang, T., Yatskar, M., Ordonez, V., & Chang, K.-W. (2017). *Men Also Like Shopping: Reducing Gender Bias Amplification using Corpus-level Constraints* (arXiv:1707.09457). arXiv. [https://doi.org/10.48550/arXiv.1707.09457](https://doi.org/10.48550/arXiv.1707.09457)
